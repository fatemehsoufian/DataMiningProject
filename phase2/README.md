# Clustering Phase
The project focuses on utilizing BERT (Bidirectional Encoder Representations from Transformers), a powerful language model, to convert the textual data from the clean dataset into vector
representations. BERT is a pre-trained model that has been trained on massive amounts of text data, enabling it to understand the semantics and context of the text. By leveraging BERT,
the project aims to capture the intricate meaning and relationships within the textual data and represent them as numerical vectors.

Once the textual data has been transformed into vectors using BERT, the project proceeds to implement various clustering algorithms. Clustering algorithms group similar data points together 
based on their vector representations. The goal is to identify distinct clusters or patterns within the dataset.
